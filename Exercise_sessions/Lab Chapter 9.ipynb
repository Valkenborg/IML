{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages('e1071', repos='http://cran.us.r-project.org')\n",
    "# install.packages('ROCR', repos='http://cran.us.r-project.org')\n",
    "# install.packages('lowess', repos='http://cran.us.r-project.org')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support vector classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data set which is not linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "x=matrix(rnorm(20*2), ncol=2)    # rnorm creates normally distributed variables (here: 40 variables in 20 x 2 matrix)\n",
    "y=c(rep(-1,10), rep(1,10))   # create y-targets for first and second column\n",
    "x[y==1,]=x[y==1,] + 1    # add +1 to those points with class 1\n",
    "plot(x, col=(3-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=data.frame(x=x, y=as.factor(y))  # encode response as a factor variable to do classification (otherwise it does regression)\n",
    "library(e1071)\n",
    "svmfit=svm(y~., data=dat, kernel=\"linear\", cost=10,scale=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vectores are crosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(svmfit, dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmfit$index  # gives the indices of the support vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(svmfit)   # note: gamma is not relevant for linear kernal (= 1 / dim(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $C$ is different from the one in the book. Here, smaller $C$ means more room for error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmfit=svm(y~., data=dat, kernel=\"linear\", cost=0.1, scale=FALSE)\n",
    "plot(svmfit, dat)\n",
    "svmfit$index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform cross-validation for different $C$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "tune.out=tune(svm,y~.,data=dat,kernel=\"linear\",ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(tune.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmod=tune.out$best.model\n",
    "summary(bestmod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test data set with same properties as training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest=matrix(rnorm(20*2), ncol=2)\n",
    "ytest=sample(c(-1,1), 20, rep=TRUE)\n",
    "xtest[ytest==1,]=xtest[ytest==1,] + 1\n",
    "testdat=data.frame(x=xtest, y=as.factor(ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=predict(bestmod,testdat)\n",
    "table(predict=ypred, truth=testdat$y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmfit=svm(y~., data=dat, kernel=\"linear\", cost=.01,scale=FALSE)\n",
    "ypred=predict(svmfit,testdat)\n",
    "table(predict=ypred, truth=testdat$y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a suboptimal cost parameter leads to one more incorrect classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a data set where the classes are linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[y==1,]=x[y==1,]+0.5\n",
    "plot(x, col=(y+5)/2, pch=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=data.frame(x=x,y=as.factor(y))\n",
    "svmfit=svm(y~., data=dat, kernel=\"linear\", cost=1e5)\n",
    "summary(svmfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(svmfit, dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No errors were made. Nevertheless, we can choose to have a bigger margin to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmfit=svm(y~., data=dat, kernel=\"linear\", cost=1)\n",
    "summary(svmfit)\n",
    "plot(svmfit,dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support vector machine**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data with non-linear decision boundary, by combining three Gaussian distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "x=matrix(rnorm(200*2), ncol=2)\n",
    "x[1:100,]=x[1:100,]+2\n",
    "x[101:150,]=x[101:150,]-2\n",
    "y=c(rep(1,150),rep(2,50))\n",
    "dat=data.frame(x=x,y=as.factor(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x, col=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=sample(200,100)\n",
    "svmfit=svm(y~., data=dat[train,], kernel=\"radial\",  gamma=1, cost=1)\n",
    "plot(svmfit, dat[train,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(svmfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the cost decreases the training error. However, it will probably lead to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmfit=svm(y~., data=dat[train,], kernel=\"radial\",gamma=1,cost=1e5)\n",
    "plot(svmfit,dat[train,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)  # cross-validation to find optimal cost and gamma\n",
    "tune.out=tune(svm, y~., data=dat[train,], kernel=\"radial\", ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))\n",
    "summary(tune.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(true=dat[-train,\"y\"], pred=predict(tune.out$best.model,newdata=dat[-train,]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC curves**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a short function to plot ROC curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ROCR)\n",
    "rocplot=function(pred, truth, ...){\n",
    "   predob = prediction(pred, truth)\n",
    "   perf = performance(predob, \"tpr\", \"fpr\")\n",
    "   plot(perf,...)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmfit.opt=svm(y~., data=dat[train,], kernel=\"radial\",gamma=2, cost=1,decision.values=T)\n",
    "fitted=attributes(predict(svmfit.opt,dat[train,],decision.values=TRUE))$decision.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(1,2))\n",
    "rocplot(fitted,dat[train,\"y\"],main=\"Training Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By increasing $\\gamma$ we get a more flexible fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmfit.flex=svm(y~., data=dat[train,], kernel=\"radial\", gamma=50, cost=1, decision.values=T)\n",
    "fitted=attributes(predict(svmfit.flex,dat[train,],decision.values=T))$decision.values\n",
    "rocplot(fitted,dat[train,\"y\"],main=\"Training Data\")\n",
    "rocplot(fitted,dat[train,\"y\"],add=T,col=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we see we have made an overfit on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted=attributes(predict(svmfit.opt,dat[-train,],decision.values=T))$decision.values\n",
    "rocplot(fitted,dat[-train,\"y\"],main=\"Test Data\")\n",
    "fitted=attributes(predict(svmfit.flex,dat[-train,],decision.values=T))$decision.values\n",
    "rocplot(fitted,dat[-train,\"y\"],add=T,col=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM with multiple classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "x=rbind(x, matrix(rnorm(50*2), ncol=2))\n",
    "y=c(y, rep(0,50))\n",
    "x[y==0,2]=x[y==0,2]+2\n",
    "dat=data.frame(x=x, y=as.factor(y))\n",
    "par(mfrow=c(1,1))\n",
    "plot(x,col=(y+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmfit=svm(y~., data=dat, kernel=\"radial\", cost=10, gamma=1)\n",
    "plot(svmfit, dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Application to Gene Expression Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ISLR)\n",
    "names(Khan)\n",
    "dim(Khan$xtrain)\n",
    "dim(Khan$xtest)\n",
    "length(Khan$ytrain)\n",
    "length(Khan$ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(Khan$ytrain)\n",
    "table(Khan$ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=data.frame(x=Khan$xtrain, y=as.factor(Khan$ytrain))\n",
    "out=svm(y~., data=dat, kernel=\"linear\",cost=10)\n",
    "summary(out)\n",
    "table(out$fitted, dat$y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.te=data.frame(x=Khan$xtest, y=as.factor(Khan$ytest))\n",
    "pred.te=predict(out, newdata=dat.te)\n",
    "table(pred.te, dat.te$y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "python374jvsc74a57bd07473bcff2b0bdc7ef48ea757de80b136b964a90312b58ce2b1163701067edbb0"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
